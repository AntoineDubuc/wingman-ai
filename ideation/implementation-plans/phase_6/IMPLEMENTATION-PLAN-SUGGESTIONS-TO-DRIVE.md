# Implementation Plan: Save AI Suggestions to Google Drive Transcripts

---

## Executive Summary

AI suggestions generated by Gemini during Google Meet calls appear in the overlay UI but are never saved to Google Drive transcripts. The `TranscriptCollector` only stores Deepgram speech-to-text entries and tracks suggestions as a simple counter (`suggestionsCount: number`). All three Drive formatters (Markdown, plain text, JSON) only iterate over speech entries. This implementation stores the full text of each suggestion chronologically alongside speech transcripts, producing a complete record of the call experience — both what was said and what the AI recommended.

**Key Outcomes:**
- AI suggestion text saved to Google Drive transcripts alongside speech entries
- Suggestions appear in chronological order relative to the speech that triggered them
- Visual distinction between speech and suggestions in all three export formats (Markdown, text, JSON)
- Metadata (speaker counts, transcript counts) correctly excludes suggestion entries
- No changes to UI, overlay, or real-time suggestion display

---

## Product Manager Review

### Feature Overview

When a user ends a Wingman session, the transcript auto-saved to Google Drive currently contains only what was spoken. The AI suggestions that appeared in the overlay — the core value of the product — are lost. This feature preserves them in the Drive file so users can review exactly what Wingman recommended during the call.

### Features

#### Feature 1: Suggestion Text Persistence

**What it is:** Store the full text of each AI suggestion in the transcript collector, in chronological order alongside speech entries.

**Why it matters:** The Drive transcript is the permanent record of the call. Without suggestions, users lose the AI coaching content after the overlay closes. Sales managers reviewing transcripts can't see what guidance was provided.

**User perspective:** No behavior change during the call. After the call, the Google Drive transcript now includes Wingman's suggestions inline with the conversation, clearly labeled.

---

#### Feature 2: Distinct Suggestion Rendering in Drive Exports

**What it is:** All three export formats (Markdown, plain text, JSON) render suggestions with visual distinction from speech — different formatting, labels, and metadata fields.

**Why it matters:** Users scanning a transcript need to instantly distinguish between "what was said" and "what Wingman suggested." Mixing them without visual cues would be confusing.

**User perspective:** In Markdown, suggestions appear as labeled blockquotes. In plain text, they have a `>> WINGMAN AI` prefix. In JSON, they carry `is_suggestion: true` and `suggestion_type` fields for programmatic filtering.

---

## Master Checklist

### Instructions for Claude Code

> **CRITICAL: You must follow these rules exactly.**
>
> 1. **Save after every cell write.** You cannot batch writes to this table. Each time you update a cell (start time, end time, estimate, etc.), you must save the file immediately before proceeding to other cells or other work.
>
> 2. **Check the checkbox** when you begin a task. This serves as a visual indicator of which task is currently in progress.
>
> 3. **Workflow for each task:**
>    - Check the checkbox `[x]` → Save
>    - Write start time → Save
>    - Complete the implementation work
>    - Write end time → Save
>    - Calculate and write total time → Save
>    - Write human time estimate → Save
>    - Calculate and write multiplier → Save
>    - Move to next task
>
> 4. **Time format:** Use `HH:MM` (24-hour format) for start/end times. Use minutes for total time and estimates.
>
> 5. **Multiplier calculation:** `Multiplier = Human Estimate ÷ Total Time`. Express as `Nx` (e.g., `10x` means 10 times faster than human estimate).
>
> 6. **If blocked:** Note the blocker in the task description section below and move to the next unblocked task.

### Progress Dashboard

| Done | # | Task Name | Start | End | Total (min) | Human Est. (min) | Multiplier |
|:----:|:-:|-----------|:-----:|:---:|:-----------:|:----------------:|:----------:|
| [ ] | 1 | Add suggestion fields to CollectedTranscript and addSuggestion() | | | | 20 | |
| [ ] | 2 | Wire service worker to store suggestion text | | | | 15 | |
| [ ] | 3 | Update DriveService TranscriptData and formatters | | | | 30 | |
| [ ] | 4 | Fix metadata counts to exclude suggestions | | | | 10 | |
| [ ] | 5 | Remove debug artifacts from content script | | | | 5 | |
| [ ] | 6 | Build and validate end-to-end | | | | 10 | |

**Summary:**
- Total tasks: 6
- Completed: 0
- Total time spent: 0 minutes
- Total human estimate: 90 minutes
- Overall multiplier: --

---

## Task Descriptions

This section provides context for each task. Read the relevant description before starting implementation.

---

### Task 1: Add suggestion fields to CollectedTranscript and addSuggestion()

**Intent:** Extend the transcript collector to store full suggestion text alongside speech entries, maintaining chronological order.

**Context:** Currently `TranscriptCollector` has `incrementSuggestions()` which only bumps a counter. The `CollectedTranscript` interface only has speech fields. We need optional fields to mark entries as suggestions and a new method to create them.

**Expected behavior:**

1. Add two optional fields to `CollectedTranscript`:
   ```typescript
   is_suggestion?: boolean;
   suggestion_type?: string;
   ```

2. Add `addSuggestion()` method to `TranscriptCollector`:
   ```typescript
   addSuggestion(suggestion: {
     text: string;
     suggestion_type: string;
     timestamp: string;
   }): void {
     if (!this.session) return;

     this.session.transcripts.push({
       timestamp: suggestion.timestamp,
       speaker: 'Wingman AI',
       speaker_id: -1,
       speaker_role: 'assistant',
       text: suggestion.text,
       is_self: false,
       is_suggestion: true,
       suggestion_type: suggestion.suggestion_type,
     });

     this.session.suggestionsCount++;
     console.log(`[TranscriptCollector] Collected suggestion #${this.session.suggestionsCount}`);
   }
   ```

3. Remove the old `incrementSuggestions()` method.

**Key components:**
- `src/services/transcript-collector.ts`

**Notes:** Using `speaker_id: -1` ensures suggestions never collide with real Deepgram speaker IDs (0, 1, ...). Using `speaker_role: 'assistant'` distinguishes from `'consultant'` and `'customer'`. The `suggestionsCount` field remains for metadata display.

---

### Task 2: Wire service worker to store suggestion text

**Intent:** Replace the `incrementSuggestions()` call in the service worker with `addSuggestion()` so suggestion text is persisted.

**Context:** In `handleTranscript()` (~line 355 of `service-worker.ts`), when Gemini returns a suggestion, the code currently calls `transcriptCollector.incrementSuggestions()`. This must change to pass the full suggestion object.

**Expected behavior:**

Replace:
```typescript
transcriptCollector.incrementSuggestions();
```

With:
```typescript
transcriptCollector.addSuggestion({
  text: suggestion.text,
  suggestion_type: suggestion.suggestion_type,
  timestamp: suggestion.timestamp,
});
```

The Gemini `Suggestion` interface already has all three fields:
```typescript
interface Suggestion {
  text: string;
  suggestion_type: 'answer' | 'question' | 'objection' | 'info';
  timestamp: string;
  // ... other fields
}
```

**Key components:**
- `src/background/service-worker.ts` — `handleTranscript()` function

**Notes:** Single-line replacement. No other callers of `incrementSuggestions()` exist.

---

### Task 3: Update DriveService TranscriptData and formatters

**Intent:** Add suggestion fields to the Drive service's `TranscriptData` interface and update all three formatters to render suggestions with visual distinction from speech.

**Context:** `DriveService` has three formatters — `formatMarkdown()`, `formatText()`, `formatJson()`. All currently iterate over `TranscriptData[]` assuming every entry is speech. Suggestions now appear in the same array and need distinct rendering.

**Expected behavior:**

**Update `TranscriptData` interface:**
```typescript
export interface TranscriptData {
  timestamp: string;
  speaker: string;
  speaker_id: number;
  speaker_role: string;
  text: string;
  is_self: boolean;
  is_suggestion?: boolean;
  suggestion_type?: string;
}
```

**Update `formatMarkdown()` — in the transcript loop, add suggestion handling before the existing speech logic:**
```typescript
for (const t of transcripts) {
  if (t.is_suggestion) {
    lines.push(`> **Wingman AI** *(${t.suggestion_type || 'suggestion'})* — ${t.timestamp}`);
    lines.push(`> ${t.text}`);
    lines.push('');
    currentSpeaker = '';  // reset so next speech entry gets a header
    continue;
  }
  // ... existing speech rendering (unchanged)
}
```

**Update `formatText()` — same pattern:**
```typescript
for (const t of transcripts) {
  if (t.is_suggestion) {
    lines.push(`[${t.timestamp}] ** WINGMAN AI (${t.suggestion_type || 'suggestion'}) **`);
    lines.push(`  >> ${t.text}`);
    lines.push('');
    continue;
  }
  // ... existing speech rendering (unchanged)
}
```

**Update `formatJson()` — include optional fields in transcript entries:**
```typescript
transcripts: transcripts.map((t) => ({
  timestamp: t.timestamp,
  speaker: t.speaker,
  speaker_id: t.speaker_id,
  speaker_role: t.speaker_role,
  text: t.text,
  is_self: t.is_self,
  ...(t.is_suggestion && {
    is_suggestion: true,
    suggestion_type: t.suggestion_type,
  }),
})),
```

**Key components:**
- `src/services/drive-service.ts` — `TranscriptData` interface, `formatMarkdown()`, `formatText()`, `formatJson()`

**Notes:** The `currentSpeaker = ''` reset in Markdown ensures that after a suggestion, the next speech entry always gets a fresh speaker header, maintaining readability.

---

### Task 4: Fix metadata counts to exclude suggestions

**Intent:** Ensure `transcriptsCount` and `speakersCount` in `SessionMetadata` reflect only speech entries, not suggestions.

**Context:** In `handleStopSession()`, the code builds `SessionMetadata` from `sessionData.transcripts`. Now that suggestions are in the same array, counting all entries would inflate `transcriptsCount` and `speakersCount` (the "Wingman AI" pseudo-speaker with `speaker_id: -1` would be counted).

**Expected behavior:**

In `handleStopSession()` (~line 460 of `service-worker.ts`):

1. **Update TranscriptData mapping** to include new fields:
   ```typescript
   const transcripts: TranscriptData[] = sessionData.transcripts.map((t) => ({
     timestamp: t.timestamp,
     speaker: t.speaker,
     speaker_id: t.speaker_id,
     speaker_role: t.speaker_role,
     text: t.text,
     is_self: t.is_self,
     is_suggestion: t.is_suggestion,
     suggestion_type: t.suggestion_type,
   }));
   ```

2. **Filter for speech-only when computing counts:**
   ```typescript
   const speechTranscripts = sessionData.transcripts.filter((t) => !t.is_suggestion);
   const speakerIds = new Set(speechTranscripts.map((t) => t.speaker_id));

   const metadata: SessionMetadata = {
     startTime: sessionData.startTime,
     endTime,
     durationSeconds,
     speakersCount: speakerIds.size,
     transcriptsCount: speechTranscripts.length,
     suggestionsCount: sessionData.suggestionsCount,
     speakerFilterEnabled: sessionData.speakerFilterEnabled,
   };
   ```

**Key components:**
- `src/background/service-worker.ts` — `handleStopSession()` function

**Notes:** Also update the summary guard on line 418 to use `speechTranscripts.length` instead of `sessionData.transcripts.length`:
```typescript
} else if (!sessionData || speechTranscripts.length < 5) {
```
This ensures the "< 5 transcripts" check counts speech only, not suggestions.

---

### Task 5: Remove debug artifacts from content script

**Intent:** Clean up the debug red banner and verbose delivery logging added during overlay troubleshooting.

**Context:** During the previous debugging session, a bright red "WINGMAN OVERLAY LOADED" banner was added to `content-script.ts` (lines 81-92) and verbose `console.debug`/`console.log` calls were added to `service-worker.ts` for message delivery tracking. These should be removed.

**Expected behavior:**

1. In `content-script.ts` `initOverlay()`: Remove lines 81-92 (the `diag` div creation, styling, append, and setTimeout removal).

2. In `service-worker.ts` `handleTranscript()`: Simplify the transcript/suggestion sendMessage calls back to `.catch(() => {})` — or keep error logging but remove the `.then(resp => console.debug(...))` success logging.

**Key components:**
- `src/content/content-script.ts` — `initOverlay()` function
- `src/background/service-worker.ts` — `handleTranscript()` function

**Notes:** Keep the defensive overlay fixes (inline styles, `document.documentElement` append, `ensureOverlayAttached()`, `forceShow()`) — those are legitimate improvements. Only remove the diagnostic banner and verbose delivery logging.

---

### Task 6: Build and validate end-to-end

**Intent:** Run the full build pipeline and verify everything compiles cleanly.

**Context:** Depends on all previous tasks. Catches type mismatches, missing imports, and build errors.

**Expected behavior:**
- `npm run typecheck` passes with zero errors
- `npm run build` produces clean dist
- No remaining references to `incrementSuggestions()` in the codebase
- `TranscriptData` and `CollectedTranscript` interfaces are aligned

**Key components:**
- All files from Tasks 1-5

**Notes:** Full live validation requires a Google Meet call. Verify: (1) Start session, speak enough to trigger a Gemini suggestion, (2) Stop session, (3) Check Drive file — suggestions should appear inline with speech, visually distinct. Check all three formats if possible (Markdown is the default).

---

## Appendix

### Technical Decisions

**Unified timeline (suggestions in same array as speech) over separate array:** Storing suggestions in a separate `suggestions[]` array would lose chronological context — you wouldn't know which speech triggered which suggestion. The unified approach preserves order naturally and requires no timestamp-based merge logic in formatters. The `is_suggestion` boolean cleanly distinguishes entry types.

**`speaker_id: -1` for suggestions:** Deepgram assigns non-negative speaker IDs (0, 1, ...). Using `-1` guarantees no collision and makes filtering trivial (`!t.is_suggestion` or `t.speaker_id >= 0`).

**Keep `suggestionsCount` in SessionData:** Even though we could derive it by counting `is_suggestion: true` entries, the explicit counter is useful for quick metadata access without filtering the full array.

### Dependencies

No new dependencies. All changes are internal to existing modules.

### Out of Scope

- **Suggestion formatting in the overlay** — Already working, no changes needed
- **Knowledge Base source attribution in Drive exports** — The `kbSource` field from suggestions could be included but adds complexity; defer to a future phase
- **Retroactive backfill** — Existing Drive transcripts won't be updated; only new sessions get suggestions
- **Suggestion confidence/source in Drive exports** — Could include `confidence` and `source` fields but would clutter the transcript; defer unless requested
