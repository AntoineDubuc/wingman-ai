# Presales AI Assistant - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED: API Keys
# =============================================================================

# Deepgram API Key (Speech-to-Text)
# Get your key at: https://console.deepgram.com/
# Uses Nova-3 model for best accuracy
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Google Gemini API Key (LLM)
# Get your key at: https://aistudio.google.com/apikey
# Uses gemini-2.5-flash model
GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# BACKEND CONFIGURATION
# =============================================================================

# Server settings
HOST=0.0.0.0
PORT=8000
DEBUG=false

# WebSocket URL (for extension to connect)
# In development: ws://localhost:8000/ws/session
# In production: wss://your-domain.com/ws/session
BACKEND_WS_URL=ws://localhost:8000/ws/session

# CORS Origins (comma-separated)
# Include your Chrome extension ID for production
CORS_ORIGINS=chrome-extension://*,http://localhost:*

# =============================================================================
# GOOGLE DRIVE INTEGRATION (Optional)
# =============================================================================

# Google OAuth credentials for Drive integration
# Create at: https://console.cloud.google.com/apis/credentials
# 1. Create OAuth 2.0 Client ID (Web application type)
# 2. Add authorized redirect URI: http://localhost:8000/auth/google/callback
# 3. Enable Google Drive API in your project
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=

# Backend URL for OAuth redirect (must match your redirect URI)
BACKEND_URL=http://localhost:8000

# =============================================================================
# RAG / KNOWLEDGE BASE CONFIGURATION
# =============================================================================

# Collection name for vector database
RAG_COLLECTION_NAME=presales_knowledge

# Embedding model
# Options: gemini-embedding-001 (recommended), embeddinggemma-300m (on-device)
EMBEDDING_MODEL=gemini-embedding-001

# Vector database settings (development uses ChromaDB locally)
CHROMA_PERSIST_DIRECTORY=./data/chroma

# =============================================================================
# PRODUCTION ONLY: Pinecone (uncomment when deploying)
# =============================================================================

# PINECONE_API_KEY=your_pinecone_api_key_here
# PINECONE_ENVIRONMENT=us-east-1
# PINECONE_INDEX_NAME=presales-knowledge

# =============================================================================
# OPTIONAL: Monitoring & Logging
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Sentry DSN for error tracking (optional)
# SENTRY_DSN=https://your_sentry_dsn_here

# =============================================================================
# TRANSCRIPTION SETTINGS
# =============================================================================

# Deepgram model options: nova-3, nova-2-meeting, flux-general-en
DEEPGRAM_MODEL=nova-3

# Audio settings
AUDIO_SAMPLE_RATE=16000
AUDIO_CHANNELS=1

# Enable speaker diarization (identifies who is speaking)
ENABLE_DIARIZATION=true

# =============================================================================
# LLM SETTINGS
# =============================================================================

# Gemini model: gemini-2.5-flash (fast), gemini-2.5-pro (higher quality)
GEMINI_MODEL=gemini-2.5-flash

# Response settings
MAX_RESPONSE_TOKENS=500
TEMPERATURE=0.3
